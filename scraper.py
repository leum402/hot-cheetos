# -*- coding: utf-8 -*-
"""
í† ìŠ¤ ì‹¤ì‹œê°„ ê¸‰ë“±ì£¼ + ì‹¤ì œ ë‰´ìŠ¤ í¬ë¡¤ë§ ë° AI ìš”ì•½
- Google News RSSë¡œ 24ì‹œê°„ ì´ë‚´ ë‰´ìŠ¤ ìˆ˜ì§‘
- OpenAI GPTë¡œ í˜¸ì¬/ì•…ì¬ ë¶„ì„
- 1ì‹œê°„ ìºì‹±ìœ¼ë¡œ API ë¹„ìš© ì ˆê°
- ì‹¤ì œ ë‰´ìŠ¤ ë§í¬ ì œê³µ
"""

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup

import os
import re
import time
import json
import random
import requests
import shutil
import subprocess
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta
from typing import Dict, Optional, Tuple, List
from urllib.parse import quote_plus
from dotenv import load_dotenv

# =========================
# í™˜ê²½ë³€ìˆ˜
# =========================
load_dotenv()
API_URL = os.getenv("API_URL", "http://127.0.0.1:8080/api/update")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
OPENAI_TIMEOUT = float(os.getenv("OPENAI_TIMEOUT", "12"))
OPENAI_RETRIES = int(os.getenv("OPENAI_RETRIES", "2"))
MAX_LINE_LEN = int(os.getenv("NEWS_MAX_LINE_LEN", "50"))
CACHE_DURATION_MINUTES = int(os.getenv("NEWS_CACHE_MINUTES", "60"))

# =========================
# ë‰´ìŠ¤ ìºì‹œ ì‹œìŠ¤í…œ
# =========================
class NewsCache:
    """1ì‹œê°„ ë™ì•ˆ ë‰´ìŠ¤ ìºì‹±í•˜ì—¬ API ë¹„ìš© ì ˆê°"""
    def __init__(self, cache_duration_minutes: int = 60):
        self.cache: Dict[str, Tuple[dict, datetime]] = {}
        self.cache_duration = timedelta(minutes=cache_duration_minutes)
        self.cache_file = "news_cache.json"
        self.load_cache()

    def load_cache(self):
        """ì €ì¥ëœ ìºì‹œ íŒŒì¼ ë¡œë“œ"""
        if os.path.exists(self.cache_file):
            try:
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                now = datetime.now()
                for stock, (value, ts_str) in data.items():
                    ts = datetime.fromisoformat(ts_str)
                    if now - ts < self.cache_duration:
                        self.cache[stock] = (value, ts)
                print(f"ğŸ“¦ ìºì‹œ ë¡œë“œ: {len(self.cache)}ê°œ ì¢…ëª©", flush=True)
            except Exception as e:
                print(f"âš ï¸ ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}", flush=True)

    def save_cache(self):
        """ìºì‹œë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            data = {}
            for stock, (value, ts) in self.cache.items():
                # ë¬¸ìì—´ì´ë©´ êµ¬ í˜•ì‹, dictë©´ ì‹  í˜•ì‹
                if isinstance(value, str):
                    # êµ¬ í˜•ì‹ì„ ì‹  í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                    value = {
                        "summary": value,
                        "bullish_url": "",
                        "bearish_url": "",
                        "sources": []
                    }
                data[stock] = (value, ts.isoformat())
            
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}", flush=True)

    def get(self, stock_name: str) -> Optional[dict]:
        """ìºì‹œì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        if stock_name in self.cache:
            value, cached_time = self.cache[stock_name]
            if datetime.now() - cached_time < self.cache_duration:
                remaining = self.cache_duration - (datetime.now() - cached_time)
                print(f"    ğŸ’¾ ìºì‹œ ì‚¬ìš©: {stock_name} (ë‚¨ì€ì‹œê°„: {remaining.seconds//60}ë¶„)", flush=True)
                # ë¬¸ìì—´ì´ë©´ êµ¬ í˜•ì‹, dictë©´ ì‹  í˜•ì‹
                if isinstance(value, str):
                    return {
                        "summary": value,
                        "bullish_url": "",
                        "bearish_url": "",
                        "sources": []
                    }
                return value
            else:
                del self.cache[stock_name]
        return None

    def set(self, stock_name: str, value: dict):
        """ìºì‹œì— ë°ì´í„° ì €ì¥"""
        self.cache[stock_name] = (value, datetime.now())
        self.save_cache()

    def cleanup(self):
        """ë§Œë£Œëœ ìºì‹œ ì •ë¦¬"""
        now = datetime.now()
        expired = [stock for stock, (_, ts) in self.cache.items() 
                  if now - ts >= self.cache_duration]
        for stock in expired:
            del self.cache[stock]
        if expired:
            print(f"ğŸ—‘ï¸ ë§Œë£Œ ìºì‹œ ì •ë¦¬: {len(expired)}ê°œ", flush=True)
            self.save_cache()

# ì „ì—­ ìºì‹œ ì¸ìŠ¤í„´ìŠ¤
news_cache = NewsCache(CACHE_DURATION_MINUTES)

# =========================
# í¬ë¡¬ ë“œë¼ì´ë²„ ì„¤ì •
# =========================
def setup_driver():
    print("ğŸŒ Chrome ë“œë¼ì´ë²„ ì„¤ì • ì‹œì‘...", flush=True)
    
    options = Options()
    
    # í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ
    options.add_argument('--headless')
    options.add_argument('--disable-gpu')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-setuid-sandbox')
    options.add_argument('--window-size=1920,1080')
    
    # ì¶”ê°€ ì˜µì…˜
    options.add_argument('--disable-blink-features=AutomationControlled')
    options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
    
    try:
        # chromedriver ê²½ë¡œ ì°¾ê¸°
        chromedriver_path = shutil.which('chromedriver')
        if chromedriver_path:
            print(f"âœ… ì‹œìŠ¤í…œ chromedriver ë°œê²¬: {chromedriver_path}", flush=True)
            service = Service(chromedriver_path)
        else:
            # ì¼ë°˜ì ì¸ ê²½ë¡œë“¤ ì‹œë„
            possible_paths = [
                '/usr/bin/chromedriver',
                '/usr/local/bin/chromedriver',
                '/opt/chromedriver/chromedriver'
            ]
            
            for path in possible_paths:
                if os.path.exists(path):
                    print(f"âœ… chromedriver ë°œê²¬: {path}", flush=True)
                    service = Service(path)
                    break
            else:
                raise Exception("chromedriverë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        driver = webdriver.Chrome(service=service, options=options)
        print("âœ… Chrome ë“œë¼ì´ë²„ ìƒì„± ì™„ë£Œ", flush=True)
        
        return driver
        
    except Exception as e:
        print(f"âŒ Chrome ë“œë¼ì´ë²„ ì„¤ì • ì‹¤íŒ¨: {e}", flush=True)
        raise

# =========================
# Google News RSSì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘
# =========================
def fetch_google_news(stock_name: str, max_items: int = 5) -> List[dict]:
    """Google News RSSì—ì„œ 24ì‹œê°„ ì´ë‚´ ë‰´ìŠ¤ ìˆ˜ì§‘"""
    query = quote_plus(f"{stock_name} when:1d")
    url = f"https://news.google.com/rss/search?q={query}&hl=ko&gl=KR&ceid=KR:ko"
    headers = {'User-Agent': 'Mozilla/5.0'}
    
    try:
        resp = requests.get(url, headers=headers, timeout=5)
        resp.raise_for_status()
    except Exception as e:
        print(f"    âš ï¸ ë‰´ìŠ¤ RSS ì‹¤íŒ¨: {e}", flush=True)
        return []
    
    items = []
    try:
        root = ET.fromstring(resp.content)
        for item in root.findall(".//item"):
            title_el = item.find("title")
            link_el = item.find("link")
            pub_el = item.find("pubDate")
            
            if title_el is not None and link_el is not None:
                title = title_el.text.strip()
                link = link_el.text.strip()
                published = pub_el.text.strip() if pub_el is not None else ""
                
                # ë£¨ë¨¸ë‚˜ ì¶”ì •ì„± ê¸°ì‚¬ ì œì™¸
                if any(k in title for k in ["ë£¨ë¨¸", "ì¶”ì •", "ì†Œë¬¸", "ì „ë§ë§Œ", "ì˜ˆìƒë§Œ"]):
                    continue
                
                items.append({
                    "title": title,
                    "link": link,
                    "published": published
                })
                
                if len(items) >= max_items:
                    break
    except Exception as e:
        print(f"    âš ï¸ RSS íŒŒì‹± ì‹¤íŒ¨: {e}", flush=True)
    
    return items

# =========================
# OpenAI GPTë¡œ ë‰´ìŠ¤ ìš”ì•½
# =========================
def summarize_news_with_gpt(stock_name: str, rate: str, headlines: List[dict]) -> dict:
    """GPTë¡œ í˜¸ì¬/ì•…ì¬ ë¶„ì„ ë° ë§í¬ ë§¤í•‘"""
    
    # API í‚¤ ì—†ìœ¼ë©´ ê·œì¹™ ê¸°ë°˜ ìš”ì•½
    if not OPENAI_API_KEY:
        return rule_based_summary(stock_name, rate, headlines)
    
    # OpenAI SDK ì„í¬íŠ¸
    try:
        from openai import OpenAI
        client = OpenAI(api_key=OPENAI_API_KEY)
    except ImportError:
        print("    âš ï¸ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ", flush=True)
        return rule_based_summary(stock_name, rate, headlines)
    except Exception as e:
        print(f"    âš ï¸ OpenAI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", flush=True)
        return rule_based_summary(stock_name, rate, headlines)
    
    # í—¤ë“œë¼ì¸ í¬ë§·íŒ…
    headlines_text = "\n".join([
        f"{i}. {h['title']}" 
        for i, h in enumerate(headlines, 1)
    ]) if headlines else "ë‰´ìŠ¤ ì—†ìŒ"
    
    # GPT í”„ë¡¬í”„íŠ¸
    system_prompt = (
        "ë„ˆëŠ” í•œêµ­ ì£¼ì‹ ë‰´ìŠ¤ ë¶„ì„ ì „ë¬¸ê°€ë‹¤. "
        "ì‹¤ì œ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ì„ ê¸°ë°˜ìœ¼ë¡œ í˜¸ì¬ì™€ ì•…ì¬ë¥¼ ê°ê° í•œ ì¤„ë¡œ ìš”ì•½í•œë‹¤. "
        "ê° ì¤„ì€ 50ì ì´ë‚´ë¡œ ì‘ì„±í•œë‹¤."
    )
    
    user_prompt = f"""
ì¢…ëª©: {stock_name}
ë“±ë½ë¥ : {rate}
ì˜¤ëŠ˜ ë‰´ìŠ¤ í—¤ë“œë¼ì¸:
{headlines_text}

ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ë¼:
{{
  "bullish": "í˜¸ì¬ ë‚´ìš© í•œ ì¤„",
  "bearish": "ì•…ì¬ ë‚´ìš© í•œ ì¤„",
  "bullish_idx": 1,
  "bearish_idx": 2
}}

bullish_idxëŠ” í˜¸ì¬ ê·¼ê±°ê°€ ë˜ëŠ” í—¤ë“œë¼ì¸ ë²ˆí˜¸ (1ë¶€í„° ì‹œì‘)
bearish_idxëŠ” ì•…ì¬ ê·¼ê±°ê°€ ë˜ëŠ” í—¤ë“œë¼ì¸ ë²ˆí˜¸
ê·¼ê±°ê°€ ì—†ìœ¼ë©´ í•´ë‹¹ idxëŠ” nullë¡œ ì„¤ì •
"""
    
    # GPT í˜¸ì¶œ (ì¬ì‹œë„ í¬í•¨)
    for attempt in range(OPENAI_RETRIES + 1):
        try:
            response = client.chat.completions.create(
                model=OPENAI_MODEL,
                temperature=0.3,
                max_tokens=200,
                timeout=OPENAI_TIMEOUT,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ]
            )
            
            content = response.choices[0].message.content.strip()
            
            # JSON íŒŒì‹±
            if content.startswith("```"):
                content = content.strip("`").strip()
                if content.startswith("json"):
                    content = content[4:].strip()
            
            data = json.loads(content)
            
            # ê²°ê³¼ í¬ë§·íŒ…
            bullish = data.get('bullish', 'íŠ¹ë³„í•œ í˜¸ì¬ ì—†ìŒ')
            bearish = data.get('bearish', 'íŠ¹ë³„í•œ ì•…ì¬ ì—†ìŒ')
            bull_idx = data.get('bullish_idx')
            bear_idx = data.get('bearish_idx')
            
            # ë§í¬ ë§¤í•‘
            bull_url = ""
            bear_url = ""
            if bull_idx and headlines and 1 <= bull_idx <= len(headlines):
                bull_url = headlines[bull_idx - 1]['link']
            if bear_idx and headlines and 1 <= bear_idx <= len(headlines):
                bear_url = headlines[bear_idx - 1]['link']
            
            # ê¸¸ì´ ì œí•œ
            if len(bullish) > MAX_LINE_LEN:
                bullish = bullish[:MAX_LINE_LEN-1] + "â€¦"
            if len(bearish) > MAX_LINE_LEN:
                bearish = bearish[:MAX_LINE_LEN-1] + "â€¦"
            
            return {
                "summary": f"ğŸŸ¢ í˜¸ì¬: {bullish}\nğŸ”´ ì•…ì¬: {bearish}",
                "bullish_url": bull_url,
                "bearish_url": bear_url,
                "sources": headlines
            }
            
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            return rule_based_summary(stock_name, rate, headlines)
        except Exception as e:
            if attempt < OPENAI_RETRIES:
                print(f"    âš ï¸ GPT ì¬ì‹œë„ {attempt+1}/{OPENAI_RETRIES}", flush=True)
                time.sleep(1)
            else:
                print(f"    âš ï¸ GPT ìµœì¢… ì‹¤íŒ¨: {e}", flush=True)
                return rule_based_summary(stock_name, rate, headlines)
    
    return rule_based_summary(stock_name, rate, headlines)

# =========================
# ê·œì¹™ ê¸°ë°˜ ìš”ì•½ (í´ë°±)
# =========================
def rule_based_summary(stock_name: str, rate: str, headlines: List[dict]) -> dict:
    """GPT ì‚¬ìš© ë¶ˆê°€ ì‹œ ê·œì¹™ ê¸°ë°˜ ìš”ì•½"""
    if headlines and len(headlines) > 0:
        # ì²« ë²ˆì§¸ ë‰´ìŠ¤ë¥¼ í˜¸ì¬ë¡œ
        bullish = headlines[0]['title'][:MAX_LINE_LEN-8]
        bull_url = headlines[0]['link']
        
        # ë‘ ë²ˆì§¸ ë‰´ìŠ¤ë¥¼ ì•…ì¬ë¡œ (ì—†ìœ¼ë©´ ì¼ë°˜ ë©”ì‹œì§€)
        if len(headlines) > 1:
            bearish = headlines[1]['title'][:MAX_LINE_LEN-8]
            bear_url = headlines[1]['link']
        else:
            bearish = "ë‹¨ê¸° ë³€ë™ì„± ì£¼ì˜"
            bear_url = ""
    else:
        # ë‰´ìŠ¤ê°€ ì—†ì„ ë•Œ
        try:
            rate_value = float(rate.replace('%', '').replace('+', ''))
            if rate_value > 20:
                bullish = f"{stock_name} ìƒí•œê°€ ì„ë°•"
                bearish = "ê¸‰ë“± í›„ ì¡°ì • ê°€ëŠ¥ì„±"
            elif rate_value > 10:
                bullish = f"{stock_name} ê°•ì„¸ ì§€ì†"
                bearish = "ì°¨ìµì‹¤í˜„ ë§¤ë¬¼ ëŒ€ê¸°"
            else:
                bullish = f"{stock_name} ìƒìŠ¹ì„¸"
                bearish = "ì¶”ê°€ ìƒìŠ¹ ì œí•œì "
        except:
            bullish = f"{stock_name} ê±°ë˜ëŸ‰ ì¦ê°€"
            bearish = "ë³€ë™ì„± í™•ëŒ€ ì£¼ì˜"
        
        bull_url = ""
        bear_url = ""
    
    return {
        "summary": f"ğŸŸ¢ í˜¸ì¬: {bullish}\nğŸ”´ ì•…ì¬: {bearish}",
        "bullish_url": bull_url,
        "bearish_url": bear_url,
        "sources": headlines
    }

# =========================
# ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ìš”ì•½ (ìºì‹œ í¬í•¨)
# =========================
def get_news_summary_cached(stock_name: str, rate: str) -> dict:
    """ìºì‹œë¥¼ í™œìš©í•œ ë‰´ìŠ¤ ìš”ì•½"""
    # ìºì‹œ í™•ì¸
    cached = news_cache.get(stock_name)
    if cached:
        return cached
    
    print(f"    ğŸ” ìƒˆë¡œìš´ ë‰´ìŠ¤ ê²€ìƒ‰: {stock_name}", flush=True)
    
    # Google Newsì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘
    headlines = fetch_google_news(stock_name)
    if headlines:
        print(f"    ğŸ“° {len(headlines)}ê°œ ë‰´ìŠ¤ ë°œê²¬", flush=True)
    
    # GPTë¡œ ìš”ì•½ ë˜ëŠ” ê·œì¹™ ê¸°ë°˜ ìš”ì•½
    result = summarize_news_with_gpt(stock_name, rate, headlines)
    
    # ìºì‹œ ì €ì¥
    news_cache.set(stock_name, result)
    
    return result

# =========================
# í† ìŠ¤ ë°ì´í„° íŒŒì‹±
# =========================
def parse_toss_stocks(soup):
    """í† ìŠ¤ í˜ì´ì§€ì—ì„œ ê¸‰ë“±ì£¼ ë°ì´í„° ì¶”ì¶œ"""
    stocks = []
    
    # í† ìŠ¤ ë­í‚¹ í–‰ ì°¾ê¸°
    rows = soup.select('tr[data-tossinvest-log="RankingListRow"]')
    
    if not rows:
        print("âš ï¸ ê¸°ë³¸ ì…€ë ‰í„° ì‹¤íŒ¨, tbody tr ì‹œë„", flush=True)
        rows = soup.select('tbody tr')
    
    print(f"ğŸ“Š {len(rows)}ê°œ ì¢…ëª© ë°œê²¬", flush=True)
    
    for i, row in enumerate(rows[:10], 1):
        try:
            # ì¢…ëª©ëª… ì¶”ì¶œ
            name = ""
            
            # ì—¬ëŸ¬ ì…€ë ‰í„° ì‹œë„
            name_selectors = [
                'span[class*="60z0ev1"]',
                'a[href*="/stocks/"]',
                'span[class*="stock-name"]',
                'td:nth-child(2) span'
            ]
            
            for selector in name_selectors:
                elem = row.select_one(selector)
                if elem:
                    text = elem.get_text(strip=True)
                    # ìˆ«ìë§Œ ìˆê±°ë‚˜ íŠ¹ìˆ˜ë¬¸ìë§Œ ìˆëŠ” ê²½ìš° ì œì™¸
                    if text and not text.isdigit() and not all(c in ',.%+-' for c in text):
                        name = text
                        break
            
            # ì—¬ì „íˆ ëª» ì°¾ì•˜ìœ¼ë©´ ëª¨ë“  span ê²€ìƒ‰
            if not name:
                for span in row.select('span'):
                    text = span.get_text(strip=True)
                    # ê°€ê²©ì´ë‚˜ í¼ì„¼íŠ¸ê°€ ì•„ë‹Œ í…ìŠ¤íŠ¸ ì°¾ê¸°
                    if text and not any(x in text for x in ['%', 'ì›', ',']) and len(text) > 1:
                        name = text
                        break
            
            # ê°€ê²©ê³¼ ë“±ë½ë¥  ì¶”ì¶œ
            price = "0ì›"
            rate = "+0.0%"
            
            # ìˆ«ìê°€ í¬í•¨ëœ spanë“¤ ì°¾ê¸°
            price_spans = row.select('span')
            for span in price_spans:
                text = span.get_text(strip=True)
                if 'ì›' in text and price == "0ì›":
                    price = text
                elif '%' in text and rate == "+0.0%":
                    rate = text
            
            # ì´ë¦„ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
            if not name or len(name) < 2:
                name = f"ì¢…ëª©{i}"
            
            # + ê¸°í˜¸ ì—†ìœ¼ë©´ ì¶”ê°€
            if rate and not rate.startswith(('+', '-')):
                rate = '+' + rate
            
            print(f"  {i}. {name} - {price} ({rate})", flush=True)
            
            # ì‹¤ì œ ë‰´ìŠ¤ ìš”ì•½ ê°€ì ¸ì˜¤ê¸° (ìºì‹œ í™œìš©)
            news_result = get_news_summary_cached(name, rate)
            
            stocks.append({
                "rank": i,
                "name": name,
                "price": price,
                "rate": rate,
                "summary": news_result["summary"],
                "bullish_url": news_result.get("bullish_url", ""),
                "bearish_url": news_result.get("bearish_url", ""),
                "sources": news_result.get("sources", [])
            })
            
            # ìš”ì•½ ì¶œë ¥
            for line in news_result["summary"].split('\n'):
                print(f"    {line}", flush=True)
            
        except Exception as e:
            print(f"  âŒ {i}ë²ˆ ì¢…ëª© íŒŒì‹± ì˜¤ë¥˜: {e}", flush=True)
            # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’
            stocks.append({
                "rank": i,
                "name": f"ì¢…ëª©{i}",
                "price": "0ì›",
                "rate": "+0.0%",
                "summary": "ğŸŸ¢ í˜¸ì¬: ë°ì´í„° ë¡œë”© ì¤‘\nğŸ”´ ì•…ì¬: ë°ì´í„° ë¡œë”© ì¤‘",
                "bullish_url": "",
                "bearish_url": "",
                "sources": []
            })
    
    return stocks

# =========================
# í† ìŠ¤ í¬ë¡¤ë§ ë©”ì¸
# =========================
def crawl_toss():
    """í† ìŠ¤ ê¸‰ë“±ì£¼ í˜ì´ì§€ í¬ë¡¤ë§"""
    print("\nğŸ” í† ìŠ¤ í¬ë¡¤ë§ ì‹œì‘", flush=True)
    
    driver = None
    
    try:
        driver = setup_driver()
        
        # í† ìŠ¤ ê¸‰ë“±ì£¼ í˜ì´ì§€
        url = 'https://www.tossinvest.com/?live-chart=heavy_soar'
        print(f"ğŸ“ ì ‘ì†: {url}", flush=True)
        
        driver.get(url)
        
        # í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸°
        time.sleep(5)
        
        # ë™ì  ì½˜í…ì¸  ë¡œë“œë¥¼ ìœ„í•œ ìŠ¤í¬ë¡¤
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight/2);")
        time.sleep(2)
        
        # í˜ì´ì§€ ì •ë³´
        print(f"  ì œëª©: {driver.title}", flush=True)
        print(f"  URL: {driver.current_url}", flush=True)
        
        # HTML íŒŒì‹±
        page_source = driver.page_source
        soup = BeautifulSoup(page_source, 'html.parser')
        
        # ë°ì´í„° ì¶”ì¶œ
        stocks = parse_toss_stocks(soup)
        
        if stocks:
            print(f"âœ… {len(stocks)}ê°œ ì¢…ëª© í¬ë¡¤ë§ ì„±ê³µ", flush=True)
            
            # JSON íŒŒì¼ë¡œ ì €ì¥
            with open('latest_stocks.json', 'w', encoding='utf-8') as f:
                json.dump(stocks, f, ensure_ascii=False, indent=2)
                print("ğŸ’¾ latest_stocks.json ì €ì¥ ì™„ë£Œ", flush=True)
            
            return stocks
        else:
            print("âš ï¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ", flush=True)
            return None
            
    except Exception as e:
        print(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}", flush=True)
        import traceback
        traceback.print_exc()
        return None
        
    finally:
        if driver:
            try:
                driver.quit()
                print("ğŸ§¹ ë“œë¼ì´ë²„ ì¢…ë£Œ", flush=True)
            except:
                pass

# =========================
# í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
# =========================
def generate_test_data():
    """í¬ë¡¤ë§ ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  í…ŒìŠ¤íŠ¸ ë°ì´í„°"""
    print("\nğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±", flush=True)
    
    test_stocks = [
        {"name": "ì‚¼ì„±ì „ì", "base_rate": 25, "price": 87500},
        {"name": "SKí•˜ì´ë‹‰ìŠ¤", "base_rate": 23, "price": 142300},
        {"name": "LGì—ë„ˆì§€ì†”ë£¨ì…˜", "base_rate": 21, "price": 425000},
        {"name": "ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤", "base_rate": 19, "price": 895000},
        {"name": "í˜„ëŒ€ì°¨", "base_rate": 17, "price": 245000},
        {"name": "POSCOí™€ë”©ìŠ¤", "base_rate": 16, "price": 392500},
        {"name": "ì…€íŠ¸ë¦¬ì˜¨", "base_rate": 15, "price": 178900},
        {"name": "ì¹´ì¹´ì˜¤", "base_rate": 14, "price": 58900},
        {"name": "NAVER", "base_rate": 13, "price": 185200},
        {"name": "ê¸°ì•„", "base_rate": 12, "price": 115200}
    ]
    
    # ì‹œê°„ëŒ€ë³„ë¡œ ë‹¤ë¥¸ ì¢…ëª© ì„ íƒ
    hour = datetime.now().hour
    minute = datetime.now().minute
    seed = (hour * 60 + minute) // 10
    
    random.seed(seed)
    random.shuffle(test_stocks)
    selected = test_stocks[:10]
    selected.sort(key=lambda x: x['base_rate'], reverse=True)
    
    stocks = []
    for i, st in enumerate(selected, 1):
        rate_value = st['base_rate'] + random.uniform(-2, 2)
        rate = f"+{rate_value:.2f}%"
        price = f"{st['price']:,}ì›"
        
        print(f"  {i}. {st['name']} - {price} ({rate})", flush=True)
        
        # ì‹¤ì œ ë‰´ìŠ¤ ìš”ì•½ ê°€ì ¸ì˜¤ê¸°
        news_result = get_news_summary_cached(st["name"], rate)
        
        stocks.append({
            "rank": i,
            "name": st["name"],
            "price": price,
            "rate": rate,
            "summary": news_result["summary"],
            "bullish_url": news_result.get("bullish_url", ""),
            "bearish_url": news_result.get("bearish_url", ""),
            "sources": news_result.get("sources", [])
        })
        
        # ìš”ì•½ ì¶œë ¥
        for line in news_result["summary"].split('\n'):
            print(f"    {line}", flush=True)
    
    return stocks

# =========================
# API ì „ì†¡
# =========================
def send_to_api(data):
    try:
        print(f"\nğŸ“¤ API ì „ì†¡: {API_URL}", flush=True)
        resp = requests.post(API_URL, json=data, timeout=5)
        
        if resp.status_code == 200:
            print(f"âœ… API ì „ì†¡ ì„±ê³µ ({len(data)}ê°œ ì¢…ëª©)", flush=True)
            return True
        else:
            print(f"âŒ API ì‘ë‹µ ì½”ë“œ: {resp.status_code}", flush=True)
            
    except Exception as e:
        print(f"âŒ API ì „ì†¡ ì‹¤íŒ¨: {e}", flush=True)
    
    return False

# =========================
# ë©”ì¸ ì‹¤í–‰
# =========================
if __name__ == "__main__":
    import sys
    
    # Docker/Production í™˜ê²½ì—ì„œ ìë™ ì‹¤í–‰
    if len(sys.argv) > 1 or os.environ.get('DOCKER_ENV'):
        print("\n" + "="*60, flush=True)
        print("ğŸš€ ìë™ ëª¨ë“œ ì‹¤í–‰ (Docker/Production)", flush=True)
        print(f"ì‹œê°„: {datetime.now()}", flush=True)
        print("="*60, flush=True)
        
        # OpenAI API í‚¤ í™•ì¸
        if OPENAI_API_KEY:
            print(f"âœ… OpenAI API í™œì„±í™” (ëª¨ë¸: {OPENAI_MODEL})", flush=True)
        else:
            print("âš ï¸ OpenAI API í‚¤ ì—†ìŒ - ê·œì¹™ ê¸°ë°˜ ìš”ì•½ ì‚¬ìš©", flush=True)
        
        # ìºì‹œ ì •ë¦¬
        news_cache.cleanup()
        
        # í† ìŠ¤ í¬ë¡¤ë§ ì‹œë„
        data = None
        
        try:
            data = crawl_toss()
        except Exception as e:
            print(f"âŒ í¬ë¡¤ë§ ì˜ˆì™¸: {e}", flush=True)
        
        # í¬ë¡¤ë§ ì‹¤íŒ¨ ì‹œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚¬ìš©
        if not data:
            print("\nâš ï¸ í† ìŠ¤ í¬ë¡¤ë§ ì‹¤íŒ¨, í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚¬ìš©", flush=True)
            data = generate_test_data()
        
        # API ì „ì†¡
        if data:
            send_to_api(data)
            
            # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
            print("\n" + "="*60, flush=True)
            print("ğŸ“ˆ TOP 3 ê¸‰ë“±ì£¼:", flush=True)
            for stock in data[:3]:
                print(f"\n{stock['rank']}ìœ„: {stock['name']} ({stock['rate']})", flush=True)
                summary_lines = stock['summary'].split('\n')
                for line in summary_lines:
                    print(f"  {line}", flush=True)
                if stock.get('bullish_url'):
                    print(f"  â†— í˜¸ì¬ ë§í¬: {stock['bullish_url'][:50]}...", flush=True)
                if stock.get('bearish_url'):
                    print(f"  â†— ì•…ì¬ ë§í¬: {stock['bearish_url'][:50]}...", flush=True)
        else:
            print("âŒ ì „ì†¡í•  ë°ì´í„° ì—†ìŒ", flush=True)
        
        print("\n" + "="*60, flush=True)
        print("âœ… ì‹¤í–‰ ì™„ë£Œ", flush=True)
        print("="*60, flush=True)
        
    else:
        # ë¡œì»¬ í…ŒìŠ¤íŠ¸ ëª¨ë“œ
        print("\n" + "="*60)
        print("ğŸ“Š ë¡œì»¬ í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
        print("="*60)
        
        print("\n1. í† ìŠ¤ í¬ë¡¤ë§ + ì‹¤ì œ ë‰´ìŠ¤")
        print("2. í…ŒìŠ¤íŠ¸ ë°ì´í„° + ì‹¤ì œ ë‰´ìŠ¤")
        print("3. ìºì‹œ ìƒíƒœ í™•ì¸")
        
        choice = input("\nì„ íƒ (1-3): ").strip() or "2"
        
        if choice == "1":
            data = crawl_toss()
            if data:
                print("\nâœ… í¬ë¡¤ë§ ì„±ê³µ")
                send_to_api(data)
        elif choice == "2":
            data = generate_test_data()
            if data:
                print("\nâœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±")
                send_to_api(data)
        elif choice == "3":
            print(f"\nğŸ“¦ ìºì‹œ ìƒíƒœ: {len(news_cache.cache)}ê°œ ì¢…ëª©")
            for stock, (value, ts) in list(news_cache.cache.items())[:5]:
                age = datetime.now() - ts
                print(f"  - {stock}: {age.seconds//60}ë¶„ ì „ ìºì‹œë¨")
        
        # ìºì‹œ ì €ì¥
        news_cache.save_cache()
